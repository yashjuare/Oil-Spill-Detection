{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YAVGKeJOaldU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import img_to_array, load_img\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Directorys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dir = \"G:/oil_spills_detection/Datasets\"  # Path to the original dataset\n",
        "output_dir = \"G:/oil_spills_detection/Datagen\"  # Directory to save augmented images\n",
        "validation_dir = \"G:/oil_spills_detection/Validation_data\"\n",
        "train_dir= \"G:/oil_spills_detection/train_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for class_dir in os.listdir(input_dir):\n",
        "    class_path = os.path.join(input_dir, class_dir)\n",
        "    \n",
        "    train_class_dir = os.path.join(train_dir, class_dir)\n",
        "    val_class_dir = os.path.join(validation_dir, class_dir)\n",
        "    output_class_dir =os.path.join(output_dir, class_dir)\n",
        "    \n",
        "\n",
        "    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f)) and f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    \n",
        "    train_images, val_images = train_test_split(images, test_size = 0.2 , shuffel= True, random_state = 42)\n",
        "    for img_file in train_images:\n",
        "        src = os.path.join(class_path, img_file)\n",
        "        dst = os.path.join(train_class_dir, img_file)\n",
        "        opt = os.path.join(output_class_dir, img_file)\n",
        "        shutil.copy(src,dst)\n",
        "        shutil.copy(src, opt)\n",
        "\n",
        "    for img_file in val_images:\n",
        "         src= os.path.join(class_path, img_file)\n",
        "         dst = os.path.join(val_class_dir, img_file) \n",
        "         shutil.copy(src,dst)   \n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Argumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_gen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip= True,\n",
        "    fill_mode='constant'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply argumentation on data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data augmentation completed.\n"
          ]
        }
      ],
      "source": [
        "for class_dir in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_dir)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "    augmented_class_dir = os.path.join(output_dir, class_dir)\n",
        "    os.makedirs(augmented_class_dir, exist_ok=True)\n",
        "    # Get list of training images\n",
        "    images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f)) and f.endswith(('.jpg'))]\n",
        "    num_images = len(images)\n",
        "    arg_image = [[f for f in os.listdir(augmented_class_dir) if os.path.isfile(os.path.join(augmented_class_dir, f)) and f.endswith(('.jpg'))]]\n",
        "    num_arg_images = len(arg_image)\n",
        "\n",
        "    # Desired number of images per class (adjust as needed)\n",
        "    desired_count = 2980\n",
        "\n",
        "    # Augment images if needed\n",
        "    if num_arg_images < desired_count:\n",
        "        generated_count=0\n",
        "        for img_file in images:\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            img = load_img(img_path)\n",
        "            x = img_to_array(img)\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "\n",
        "            # Generate augmented images\n",
        "            for  batch in train_data_gen.flow(x, batch_size=1, save_to_dir=augmented_class_dir, save_prefix='aug', save_format='jpg'):\n",
        "                generated_count +=1\n",
        "                if num_images + generated_count >= desired_count:\n",
        "                    break\n",
        "            if num_images + generated_count >= desired_count:\n",
        "                break  \n",
        "\n",
        "print(\"Data augmentation completed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Oil_spill_dec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
